{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langchain_experimental.tools import PythonREPLTool, PythonAstREPLTool\n",
    "import pandas as pd\n",
    "import statsmodels as sm\n",
    "\n",
    "df = pd.read_csv(\"HOUST.csv\")\n",
    "python_repl_tool = PythonAstREPLTool(locals={\"df\": df})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder, HumanMessagePromptTemplate\n",
    "import functools\n",
    "\n",
    "system_prompt = \"\"\"You are working with a pandas dataframe in Python. The name of the dataframe is `df`.\n",
    "                It is important to understand the attributes of the dataframe before working with it. This is the result of running `df.head().to_markdown()`\n",
    "\n",
    "                <df>\n",
    "                {dhead}\n",
    "                </df>\n",
    "\n",
    "                You are not meant to use only these rows to answer questions - they are meant as a way of telling you about the shape and schema of the dataframe. \n",
    "                You also do not have use only the information here to answer questions - you can run intermediate queries to do exporatory data analysis to give you more information as needed. \"\"\"\n",
    "system_prompt = system_prompt.format(dhead=df.head().to_markdown())\n",
    "\n",
    "# part of the problem might be that I'm passing a PromptTemplate object for the system_prompt here\n",
    "# not everything needs to be an openai tools agent\n",
    "def create_agent(llm: ChatOpenAI, tools: list, task: str):\n",
    "    # Each worker node will be given a name and some tools.\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            ( \"system\", system_prompt, ), # using a global system_prompt\n",
    "            HumanMessage(content=task),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "            MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "        ]\n",
    "    )\n",
    "    agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "    executor = AgentExecutor(agent=agent, tools=tools)\n",
    "    return executor\n",
    "\n",
    "# AIMessage will have all kinds of metadata, so treat it all as HumanMessage I suppose?\n",
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    return {\"messages\": [HumanMessage(content=result[\"output\"], name=name)]}\n",
    "\n",
    "# I need to write the message to state here? or is that handled automatically?\n",
    "def chain_node(state, chain, name):\n",
    "    result = chain.invoke(input={\"detail\": \"medium\"})\n",
    "    return {\"messages\": [HumanMessage(content=result.content, name=name)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini-2024-07-18\", temperature=0)\n",
    "llm_big = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "eda_task = \"Determine if the data is stationary by running an augmented dickey fuller test.\"\n",
    "eda_agent = create_agent(llm, [python_repl_tool], task=eda_task,)\n",
    "eda_node = functools.partial(agent_node, agent=eda_agent, name=\"EDA\")\n",
    "\n",
    "# add an optional differencing node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acf_task =  \"\"\"Using the data in the dataframe `df` and the package statsmodels.\n",
    "            First generate an ACF plot with zero flag set to False, display it and save it to 'acf.png'.\n",
    "            Then generate a PACF plot with zero flag set to False, display it and save it to 'pacf.png'\"\"\"\n",
    "\n",
    "# ARBITRARY CODE EXECUTION. PROCEED WITH CAUTION\n",
    "acf_agent = create_agent(llm, [python_repl_tool], task=acf_task,)\n",
    "acf_node = functools.partial(agent_node, agent=acf_agent, name=\"ACF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_template = ChatPromptTemplate.from_messages(\n",
    "    messages=[\n",
    "        SystemMessage(content='The two plots contain the autocorrelation and partial autocorrelation functions for a time series, based on these plots up to what order AR and MA terms should be considered when estimating an ARMA model for this time series?'),\n",
    "        HumanMessagePromptTemplate.from_template(\n",
    "            template=[{\"type\": \"image_url\", \"image_url\": {\"path\": \"acf.png\"}},\n",
    "                      {\"type\": \"image_url\", \"image_url\": {\"path\": \"pacf.png\"}}]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "plot_chain = plot_template | llm_big\n",
    "plot_node = functools.partial(chain_node, chain=plot_chain, name=\"PlotAnalysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_task = \"\"\"Using the data in the dataframe `df` and the package statsmodels. \n",
    "    Estimate an ARIMA model with the appropriate AR and MA terms and display the estimated model.\n",
    "    Then generate an autocorrelation and partial autocorrelation plot of the model residuals with zero flag set to False, display it and save it as 'resid_acf.png'\"\"\"\n",
    "\n",
    "# Finally generate a partial autocorrelation plot of the model residuals with zero flag set to False, display it and save it as 'resid_pacf.png'\n",
    "\n",
    "arima_agent = create_agent(llm, [python_repl_tool], task=arima_task,)\n",
    "arima_node = functools.partial(agent_node, agent=arima_agent, name=\"ARIMA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe add system role etc\n",
    "resid_template = ChatPromptTemplate.from_messages(\n",
    "    messages=[\n",
    "        SystemMessage(content=\"\"\"The plot contains the autocorrelation and partial autocorrelation of residuals from an ARIMA model.\n",
    "                      Based on the plot are any of the residual autocorrelations significant?\n",
    "                      Should additional AR or MA terms be included in the model?\"\"\"),\n",
    "        HumanMessagePromptTemplate.from_template(\n",
    "            template=[{\"type\": \"image_url\", \"image_url\": {\"path\": \"resid_acf.png\"}}]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "resid_chain = resid_template | llm_big\n",
    "resid_node = functools.partial(chain_node, chain=resid_chain, name=\"Resid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refit_task = \"\"\"The previously estimated model can be improved by adding or removing AR and/or MA terms.\n",
    "    Using the data in the dataframe `df` and the package statsmodels, estimate a new ARIMA model with a different number of AR and/or MA terms and display the estimated model.\n",
    "    Then generate an autocorrelation and partial autocorrelation plot of the model residuals with zero flag set to False, display it and save it as 'refit_acf.png'\"\"\"\n",
    "\n",
    "# Finally generate a partial autocorrelation plot of the model residuals with zero flag set to False, display it and save it as 'resid_pacf.png'\n",
    "\n",
    "refit_agent = create_agent(llm, [python_repl_tool], task=refit_task,)\n",
    "refit_node = functools.partial(agent_node, agent=refit_agent, name=\"ARIMA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "import operator\n",
    "from typing import Sequence, TypedDict\n",
    "\n",
    "# The agent state is the input to each node in the graph\n",
    "class AgentState(TypedDict):\n",
    "    # The annotation tells the graph that new messages will always be added to the current states\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    # The 'next' field indicates where to route to next\n",
    "    next: str\n",
    "\n",
    "# add a chain to the node to analyze the ACF plot?\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"EDA\", eda_node)\n",
    "workflow.add_node(\"ACF\", acf_node)\n",
    "workflow.add_node(\"PlotAnalysis\", plot_node)\n",
    "workflow.add_node(\"ARIMA\", arima_node)\n",
    "workflow.add_node(\"Resid\", resid_node)\n",
    "workflow.add_node(\"Refit\", refit_node)\n",
    "\n",
    "# conditional_edge to refit and the loop refit with resid?\n",
    "workflow.add_edge(START, \"EDA\")\n",
    "workflow.add_edge(\"EDA\", \"ACF\")\n",
    "workflow.add_edge(\"ACF\", \"PlotAnalysis\")\n",
    "workflow.add_edge(\"PlotAnalysis\", \"ARIMA\")\n",
    "workflow.add_edge(\"ARIMA\", \"Resid\")\n",
    "workflow.add_edge(\"Resid\", \"Refit\")\n",
    "workflow.add_edge(\"Refit\", END)\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.invoke({\"messages\": [HumanMessage(content=\"Run the analysis\")]})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autobox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
